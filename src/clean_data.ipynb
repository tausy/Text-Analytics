{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used to clean blog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created: 22 Feb 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "import xmltodict, json\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def convertXML(name):\n",
    "    \"\"\"\n",
    "    Converts a blog to a list of dates and posts \n",
    "    \n",
    "    name: blog title\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open (\"data/blogs/{}\".format(name), \"r\", encoding = \"ISO-8859-1\") as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "\n",
    "    data = data.replace(\"<Blog><date>\",'')\n",
    "    data = data.replace(\"</post></Blog>\",'')\n",
    "    data = data.replace('#','')\n",
    "    data = data.replace(\"</date><post>\",'#')\n",
    "    data = data.replace(\"</post><date>\",'#')\n",
    "\n",
    "    data = data.split('#')\n",
    "    #print(data)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def writeToCSV(author,name,csv_path): \n",
    "    \"\"\"\n",
    "    Returns a list of strings of the for author,age,gender,date,post\n",
    "    \n",
    "    author: author id\n",
    "    name: blog title \n",
    "    csv_path: path to csv\n",
    "    \"\"\"\n",
    "    age = name.split(\".\")[2]\n",
    "    gender = name.split(\".\")[1]\n",
    "\n",
    "    data = convertXML(name)\n",
    "    dates = data[::2]\n",
    "    dates = [d.replace(',','/') for d in dates ]\n",
    "    posts = data[1::2]\n",
    "    with open(csv_path, 'a') as writeFile:\n",
    "        csv.register_dialect('myDialect', delimiter = '#')\n",
    "        writer = csv.writer(writeFile, dialect='myDialect')\n",
    "        \n",
    "        for i in range(len(dates)):\n",
    "            #line = \"#\".join(map(str,[author,age,gender,dates[i],posts[i]]))\n",
    "            row = [author,age,gender,dates[i],posts[i]]\n",
    "            writer.writerow(row)\n",
    "            \n",
    "    writeFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write raw blog data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19320\n",
      "3489929.female.25.Student.Cancer.xml\n"
     ]
    }
   ],
   "source": [
    "#Read in blog titles\n",
    "titles = os.listdir(\"data/blogs/\")\n",
    "#titles = random.sample(titles, 1000)\n",
    "print(len(titles))\n",
    "print(titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/19320 blogs\n",
      "Processed 1000/19320 blogs\n",
      "Processed 2000/19320 blogs\n",
      "Processed 3000/19320 blogs\n",
      "Processed 4000/19320 blogs\n",
      "Processed 5000/19320 blogs\n",
      "Processed 6000/19320 blogs\n",
      "Processed 7000/19320 blogs\n",
      "Processed 8000/19320 blogs\n",
      "Processed 9000/19320 blogs\n",
      "Processed 10000/19320 blogs\n",
      "Processed 11000/19320 blogs\n",
      "Processed 12000/19320 blogs\n",
      "Processed 13000/19320 blogs\n",
      "Processed 14000/19320 blogs\n",
      "Processed 15000/19320 blogs\n",
      "Processed 16000/19320 blogs\n",
      "Processed 17000/19320 blogs\n",
      "Processed 18000/19320 blogs\n",
      "Processed 19000/19320 blogs\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'data/blogs_raw.csv'\n",
    "\n",
    "#Initialize csv file\n",
    "with open(csv_path, 'w') as writeFile:\n",
    "        csv.register_dialect('myDialect', delimiter = '#')\n",
    "        writer = csv.writer(writeFile, dialect='myDialect')\n",
    "        row = [\"author\",\"age\",\"gender\",\"date\",\"post\"]\n",
    "        writer.writerow(row)\n",
    "            \n",
    "writeFile.close()\n",
    "\n",
    "#write blogs to csv\n",
    "for i,t in enumerate(titles):\n",
    "    writeToCSV(i,t,'data/blogs_raw.csv')\n",
    "    if i%1000 == 0: print(\"Processed {}/19320 blogs\".format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CSV post data <br>\n",
    "Every post has been cleaned by:\n",
    "\n",
    "<ul>\n",
    "    <li> Removing extra spaces\n",
    "    <li> Punctuation removed\n",
    "    <li> Made lower case\n",
    "    <li> Stemmed\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pknown</th>\n",
       "      <th>Nobs</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>FreqZipfUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.98</td>\n",
       "      <td>438</td>\n",
       "      <td>1.917</td>\n",
       "      <td>7.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.96</td>\n",
       "      <td>434</td>\n",
       "      <td>1.684</td>\n",
       "      <td>2.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardwolf</td>\n",
       "      <td>0.21</td>\n",
       "      <td>428</td>\n",
       "      <td>-0.788</td>\n",
       "      <td>1.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaca</td>\n",
       "      <td>0.24</td>\n",
       "      <td>396</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>1.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aback</td>\n",
       "      <td>0.86</td>\n",
       "      <td>343</td>\n",
       "      <td>1.077</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Pknown  Nobs  Prevalence  FreqZipfUS\n",
       "0         a    0.98   438       1.917       7.309\n",
       "1  aardvark    0.96   434       1.684       2.634\n",
       "2  aardwolf    0.21   428      -0.788       1.292\n",
       "3     abaca    0.24   396      -0.706       1.593\n",
       "4     aback    0.86   343       1.077       2.496"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevanlence = pd.read_csv(\"data/prevalence.csv\")\n",
    "prevanlence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>19/August/2004</td>\n",
       "      <td>\\t          DESTINY...       you might not say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>17/August/2004</td>\n",
       "      <td>\\t          DEAR ANGEL..      you say it or yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>16/August/2004</td>\n",
       "      <td>\\t       MAIN AUR MERI TANHAI (jagjeet singh) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>14/August/2004</td>\n",
       "      <td>\\t       mail addressrs(s)  urlLink http://red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>09/August/2004</td>\n",
       "      <td>\\t       RAP- ALLRISE so stand back cause u do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author  age gender            date  \\\n",
       "0       0   16   male  19/August/2004   \n",
       "1       0   16   male  17/August/2004   \n",
       "2       0   16   male  16/August/2004   \n",
       "3       0   16   male  14/August/2004   \n",
       "4       0   16   male  09/August/2004   \n",
       "\n",
       "                                                post  \n",
       "0  \\t          DESTINY...       you might not say...  \n",
       "1  \\t          DEAR ANGEL..      you say it or yo...  \n",
       "2  \\t       MAIN AUR MERI TANHAI (jagjeet singh) ...  \n",
       "3  \\t       mail addressrs(s)  urlLink http://red...  \n",
       "4  \\t       RAP- ALLRISE so stand back cause u do...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv(\"data/blogs_raw.csv\",sep=\"#\")\n",
    "print(len(file))\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/blogs_clean.csv\", 'w') as writeFile:\n",
    "    csv.register_dialect('myDialect', delimiter = '#')\n",
    "    writer = csv.writer(writeFile, dialect='myDialect')\n",
    "    row = [\"author\",\"age\",\"gender\",\"date\",\"post\"]\n",
    "    writer.writerow(row)\n",
    "            \n",
    "writeFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author#age#gender#date#post\n",
      "\n",
      "Processed 25000/681288 blogs\n",
      "Processed 50000/681288 blogs\n",
      "Processed 75000/681288 blogs\n",
      "Processed 100000/681288 blogs\n",
      "Processed 125000/681288 blogs\n",
      "Processed 150000/681288 blogs\n",
      "Processed 175000/681288 blogs\n",
      "Processed 200000/681288 blogs\n",
      "Processed 225000/681288 blogs\n",
      "Processed 250000/681288 blogs\n",
      "Processed 275000/681288 blogs\n",
      "Processed 300000/681288 blogs\n",
      "Processed 325000/681288 blogs\n",
      "Processed 350000/681288 blogs\n",
      "Processed 375000/681288 blogs\n",
      "Processed 400000/681288 blogs\n",
      "Processed 425000/681288 blogs\n",
      "Processed 450000/681288 blogs\n",
      "Processed 475000/681288 blogs\n",
      "Processed 500000/681288 blogs\n",
      "Processed 525000/681288 blogs\n",
      "Processed 550000/681288 blogs\n",
      "Processed 575000/681288 blogs\n",
      "Processed 600000/681288 blogs\n",
      "Processed 625000/681288 blogs\n",
      "Processed 650000/681288 blogs\n",
      "Processed 675000/681288 blogs\n"
     ]
    }
   ],
   "source": [
    "with open('data/blogs_raw.csv') as read:  \n",
    "    line = read.readline()\n",
    "    print(line)\n",
    "    line = read.readline()\n",
    "    \n",
    "    with open(\"data/blogs_clean.csv\", 'a') as writeFile:\n",
    "        csv.register_dialect('myDialect', delimiter = '#')\n",
    "        writer = csv.writer(writeFile, dialect='myDialect')\n",
    "    \n",
    "        cnt = 1\n",
    "        while line:\n",
    "            line = line.strip()\n",
    "            line = line.split(\"#\")\n",
    "            post = line[4]\n",
    "            post = cleanPost(post)\n",
    "            row = [line[0],line[1],line[2],line[3],post]\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            line = read.readline()\n",
    "            cnt += 1\n",
    "            if cnt%25000 == 0: print(\"Processed {}/681288 blogs\".format(cnt))\n",
    "                \n",
    "        writeFile.close()\n",
    "        \n",
    "    read.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i make excel lasagna just ask ricotta monkey sorri lisa but that wa your onli contribut after all so much for my great idea to start diet thi weekend posh will kill me i promis to start so we can help each other but consid the fact that the girl is onli look to lose ten that she realli ca afford to i not feel too inclin to encourag her weight loss anyway i keep tell myself that when i get my gazel i will actual stick with it and use it everi day i been lust after one for a year so thi is a realist thought howev know myself i know that i will probabl be for a month and then store it under my bed never to be seen again la vie that me i want to watch tonight i saw it when it came out in theater but due to my bladder i miss a coupl of part of the movi same with harri potter three week ago i need to go see it again becaus of my useless kegel muscl my ball will go to wast of thi i am certain anyway i am wait for lisa to make up her mind as to when she want to start the movi she said earlier that she did want to watch find nemo and lo and behold she show up minut after i had start the movi and watch the whole thing weirdo lmao she just came in here wave a pencil with a peni or pay as she pronounc it eras and yell it a tallywack between her eras and my condom finger puppet we could have a realli kinki adult puppet show go on up in here'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanPost(post):\n",
    "    \n",
    "    tokens = word_tokenize(post)\n",
    "    \n",
    "    tokens = [word for word in tokens if word.isalpha()] #remove punctuation\n",
    "    tokens = [w.lower() for w in tokens] #Lower case\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(w) for w in tokens] #Stemmed\n",
    "    post_clean = \" \".join(tokens)\n",
    "    \n",
    "    return post_clean\n",
    "post = file['post'][15]\n",
    "cleanPost(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author#age#gender#date#post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0#16#male#19/August/2004#destini you might not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0#16#male#17/August/2004#dear you say it or yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0#16#male#16/August/2004#main aur meri tanhai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0#16#male#14/August/2004#mail addressr s urlli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0#16#male#09/August/2004#allris so stand back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0#16#male#09/August/2004#miss you badli i am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0#16#male#07/August/2004#hazel eye close your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0#16#male#07/August/2004#let it be me a bird h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1#25#female#29/May/2004#it been a long time co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1#25#female#30/June/2004#urllink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1#25#female#29/June/2004#yeah i wa a leeeeetl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1#25#female#28/June/2004#urllink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1#25#female#28/June/2004#happi birthday to my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1#25#female#27/June/2004#damn lasanga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1#25#female#26/June/2004#urllink what find nem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1#25#female#26/June/2004#i make excel lasagna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1#25#female#25/June/2004#oh what a busi fuck w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1#25#female#21/June/2004#so jefe come in thi m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1#25#female#20/June/2004#what is your battl cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1#25#female#20/June/2004#it been a long weeken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1#25#female#17/June/2004#i tri to do my person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1#25#female#15/June/2004#it day like thi that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1#25#female#15/June/2004#convers of the day po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1#25#female#14/June/2004#the ir suck major ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1#25#female#12/June/2004#oh my ach head it alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1#25#female#11/June/2004#i at lisa i just had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1#25#female#09/June/2004#i ca find a titl i li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1#25#female#08/June/2004#i have spent the enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1#25#female#07/June/2004#oh what a day the tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1#25#female#04/June/2004#so here the kink in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>772#15#female#23/July/2004#sooo much i could t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33354</th>\n",
       "      <td>772#15#female#23/July/2004#what happen if you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33355</th>\n",
       "      <td>772#15#female#23/July/2004#hi peopl last night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33356</th>\n",
       "      <td>772#15#female#23/July/2004#i final fix my slee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33357</th>\n",
       "      <td>772#15#female#23/July/2004#i just went to ihop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33358</th>\n",
       "      <td>772#15#female#22/July/2004#and muh blog not ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33359</th>\n",
       "      <td>772#15#female#22/July/2004#up eighteen vision ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33360</th>\n",
       "      <td>772#15#female#22/July/2004#one take note that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33361</th>\n",
       "      <td>772#15#female#22/July/2004#it jealou cuz i hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33362</th>\n",
       "      <td>772#15#female#22/July/2004#perhap the blog jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33363</th>\n",
       "      <td>772#15#female#22/July/2004#i just spent age po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33364</th>\n",
       "      <td>772#15#female#22/July/2004#today my dad come h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33365</th>\n",
       "      <td>772#15#female#22/July/2004#ok not liter thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33366</th>\n",
       "      <td>772#15#female#22/July/2004#simon spele sausag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33367</th>\n",
       "      <td>772#15#female#21/July/2004#i dun want thi to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33368</th>\n",
       "      <td>772#15#female#21/July/2004#hi all i am sad cuz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33369</th>\n",
       "      <td>772#15#female#21/July/2004#at mine mine mine m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33370</th>\n",
       "      <td>772#15#female#21/July/2004#ok be gentl with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33371</th>\n",
       "      <td>772#15#female#21/July/2004#adi is soooo cool w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33372</th>\n",
       "      <td>772#15#female#21/July/2004#well of i rebel aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33373</th>\n",
       "      <td>772#15#female#21/July/2004#hi i laura i wa inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33374</th>\n",
       "      <td>772#15#female#21/July/2004#i in heaven la la l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33375</th>\n",
       "      <td>772#15#female#21/July/2004#oh ho ho ho lookit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33376</th>\n",
       "      <td>772#15#female#21/July/2004#is what you should ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33377</th>\n",
       "      <td>772#15#female#21/July/2004#so yeah i hear the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33378</th>\n",
       "      <td>772#15#female#21/July/2004#pink of all colour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33379</th>\n",
       "      <td>772#15#female#31/July/2004#hi peopl i went to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33380</th>\n",
       "      <td>772#15#female#30/July/2004#well if you want a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33381</th>\n",
       "      <td>772#15#female#30/July/2004#oh my god not one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33382</th>\n",
       "      <td>772#15#female#30/July/2004#i blame the gay sec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33383 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             author#age#gender#date#post\n",
       "0      0#16#male#19/August/2004#destini you might not...\n",
       "1      0#16#male#17/August/2004#dear you say it or yo...\n",
       "2      0#16#male#16/August/2004#main aur meri tanhai ...\n",
       "3      0#16#male#14/August/2004#mail addressr s urlli...\n",
       "4      0#16#male#09/August/2004#allris so stand back ...\n",
       "5      0#16#male#09/August/2004#miss you badli i am l...\n",
       "6      0#16#male#07/August/2004#hazel eye close your ...\n",
       "7      0#16#male#07/August/2004#let it be me a bird h...\n",
       "8      1#25#female#29/May/2004#it been a long time co...\n",
       "9                       1#25#female#30/June/2004#urllink\n",
       "10     1#25#female#29/June/2004#yeah i wa a leeeeetl ...\n",
       "11                      1#25#female#28/June/2004#urllink\n",
       "12     1#25#female#28/June/2004#happi birthday to my ...\n",
       "13                 1#25#female#27/June/2004#damn lasanga\n",
       "14     1#25#female#26/June/2004#urllink what find nem...\n",
       "15     1#25#female#26/June/2004#i make excel lasagna ...\n",
       "16     1#25#female#25/June/2004#oh what a busi fuck w...\n",
       "17     1#25#female#21/June/2004#so jefe come in thi m...\n",
       "18     1#25#female#20/June/2004#what is your battl cr...\n",
       "19     1#25#female#20/June/2004#it been a long weeken...\n",
       "20     1#25#female#17/June/2004#i tri to do my person...\n",
       "21     1#25#female#15/June/2004#it day like thi that ...\n",
       "22     1#25#female#15/June/2004#convers of the day po...\n",
       "23     1#25#female#14/June/2004#the ir suck major ass...\n",
       "24     1#25#female#12/June/2004#oh my ach head it alm...\n",
       "25     1#25#female#11/June/2004#i at lisa i just had ...\n",
       "26     1#25#female#09/June/2004#i ca find a titl i li...\n",
       "27     1#25#female#08/June/2004#i have spent the enti...\n",
       "28     1#25#female#07/June/2004#oh what a day the tri...\n",
       "29     1#25#female#04/June/2004#so here the kink in t...\n",
       "...                                                  ...\n",
       "33353  772#15#female#23/July/2004#sooo much i could t...\n",
       "33354  772#15#female#23/July/2004#what happen if you ...\n",
       "33355  772#15#female#23/July/2004#hi peopl last night...\n",
       "33356  772#15#female#23/July/2004#i final fix my slee...\n",
       "33357  772#15#female#23/July/2004#i just went to ihop...\n",
       "33358  772#15#female#22/July/2004#and muh blog not ga...\n",
       "33359  772#15#female#22/July/2004#up eighteen vision ...\n",
       "33360  772#15#female#22/July/2004#one take note that ...\n",
       "33361  772#15#female#22/July/2004#it jealou cuz i hav...\n",
       "33362  772#15#female#22/July/2004#perhap the blog jus...\n",
       "33363  772#15#female#22/July/2004#i just spent age po...\n",
       "33364  772#15#female#22/July/2004#today my dad come h...\n",
       "33365  772#15#female#22/July/2004#ok not liter thank ...\n",
       "33366  772#15#female#22/July/2004#simon spele sausag ...\n",
       "33367  772#15#female#21/July/2004#i dun want thi to g...\n",
       "33368  772#15#female#21/July/2004#hi all i am sad cuz...\n",
       "33369  772#15#female#21/July/2004#at mine mine mine m...\n",
       "33370  772#15#female#21/July/2004#ok be gentl with th...\n",
       "33371  772#15#female#21/July/2004#adi is soooo cool w...\n",
       "33372  772#15#female#21/July/2004#well of i rebel aga...\n",
       "33373  772#15#female#21/July/2004#hi i laura i wa inv...\n",
       "33374  772#15#female#21/July/2004#i in heaven la la l...\n",
       "33375  772#15#female#21/July/2004#oh ho ho ho lookit ...\n",
       "33376  772#15#female#21/July/2004#is what you should ...\n",
       "33377  772#15#female#21/July/2004#so yeah i hear the ...\n",
       "33378  772#15#female#21/July/2004#pink of all colour ...\n",
       "33379  772#15#female#31/July/2004#hi peopl i went to ...\n",
       "33380  772#15#female#30/July/2004#well if you want a ...\n",
       "33381  772#15#female#30/July/2004#oh my god not one s...\n",
       "33382  772#15#female#30/July/2004#i blame the gay sec...\n",
       "\n",
       "[33383 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.read_csv('data/blogs_clean.csv')\n",
    "print(len(data_clean))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertXML2(name):\n",
    "\n",
    "    with open (\"data/blogs/{}\".format(name), \"r\",encoding = \"ISO-8859-1\") as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "\n",
    "    obj = xmltodict.parse(data)\n",
    "    blogs_json = json.dumps(obj)\n",
    "    blogs_json = json.loads(blogs_json)\n",
    "\n",
    "    date = blogs_json['Blog']['date']\n",
    "    post = blogs_json['Blog']['post']\n",
    "\n",
    "    for i in zip(date,post):\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = titles[1]\n",
    "with open (\"data/blogs/{}\".format(name), \"r\") as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "xml = '<root>' + data + '</root>'\n",
    "\n",
    "obj = xmltodict.parse(xml)\n",
    "blogs_json = json.dumps(obj)\n",
    "blogs_json = json.loads(blogs_json)\n",
    "\n",
    "#convertXML(xml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
